{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Chinmay Bharambe \n",
    "- Anshul Govindu \n",
    "- Chaela Moraleja \n",
    "- Candice Sanchez \n",
    "- Praveen Sharma\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using UCSD enrollment data since Fall 2022, what combination of course characteristics (fill rate, capacity, quarter) and student factors (class standing/units, which determines the enrollment start date), best predict the number of open seats, for undergraduate courses, across all departments, during first and second-pass registrations? \n",
    "\n",
    "Can these predictions be used to develop a recommendation tool that optimizes first and second-pass course selection? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project attempts to address a major challenge for UCSD students: deciding which classes to enroll in during first and second pass. UCSD’s unique “pass” enrollment system turns course selection into more of an art than a science, often leaving students uncertain about their choices or failing to enroll in certain classes. This process also involves other unusual factors, such as major priority for CSE courses. Overall, there is a definite need for a tool that maximizes students' chances of securing their desired courses.\n",
    "\n",
    "Upon initial research, we came across a research paper on using Machine Learning Methods for Course Enrollment Prediction <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) at San Diego State University. Their primary focus was to predict course enrollment rates based on demographic and academic performance data. Although these variables are not an element of our research, their methodology with student data is applicable. For example, they considered generic variables like major and prerequisites, and incorporated predictive models like classification and regression trees. Therefore, we can build on this analysis with similar ML and statistical approaches that consider more course and student-specific factors, such as the ones mentioned in the research question.\n",
    "\n",
    "We also found two projects directly related to UCSD enrollment. This project collects data on individual classes at different points in time during each term, such as Fall 2022 or Winter 2023; each term’s data is contained within its own repository <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). The project involved building a web scraping tool that scrapes web-reg about every 10 minutes and collects real-time data on information like enrolled, available, and waitlist spots. This not only offers a tool to collect our data in the future but also a great sample dataset from what has already been collected.\n",
    "\n",
    "The second project was built using the aforementioned GitHub repositories  <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). Given a course, the website takes data from specific terms and plots the course availability as a time series across various registration milestones (senior first pass, junior second pass, etc). This offers a great initial visualization of the enrollment data, and our EDA would likely produce some similar graphs. However, our objective is to quantify the relationship between student/course factors and course availability and use our analysis to develop a recommendation system that helps students prioritize courses for first and second pass. Additionally, we plan on conducting our research on data collected across 11 quarters as compared to only one quarter shown in the stated project. We believe this is significant because there may exist quarterly patterns for some classes that a single quarter would fail to grasp.\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) https://par.nsf.gov/servlets/purl/10389427 \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) https://github.com/UCSD-Historical-Enrollment-Data\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) https://www.ucsdregistration.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict that a course’s fill rate and student class standing would be the most influential combination of factors for students deciding on courses to enroll in and directly influence the number of open seats remaining during first and second pass. More specifically, we predict that courses with a higher fill rate and later enrollment period (due to higher class standing) would mean there are fewer seats available, and thus more likely to reach full capacity during first pass rather than second pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below consists of all the libraries and packages we use in this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: UCSD Historical Enrollment Data\n",
    "\n",
    "### Dataset Overview\n",
    "  - Dataset Name: UCSD Historical Enrollment Data\n",
    "  - Link to the dataset: https://github.com/UCSD-Historical-Enrollment-Data/UCSDHistEnrollData?tab=readme-ov-file\n",
    "  - Number of observations: 11 quarters of data is recorded, the number of observations for subjects across the quarters is inconsistent.\n",
    "  - Number of variables: There are 5 variables recorded: \n",
    "    - Time : The date and time the data was recorded\n",
    "    - Enrolled : Number of students enrolled\n",
    "    - Available : Number of seats available\n",
    "    - Waitlisted : number of students waitlisted\n",
    "    - Total : total seats available for the course \n",
    "\n",
    "This dataset was compiled using an automated web scraper that collected enrollment information from UC San Diego courses, spanning from Fall 2022 through to the current quarter (Winter 2025). The data is stored in CSV files that are hosted on GitHub.\n",
    "\n",
    "\n",
    "### Dataset Structure and Organization\n",
    "\n",
    "The UCSD Historical Enrollment Data is systematically organized within a GitHub repository, where each academic term is represented by a dedicated repository. This structure facilitates easy access to term-specific enrollment data. The data collection process is such that it captures enrollment statistics at regular intervals, providing a detailed view of how course enrollment evolves throughout the registration period.\n",
    "\n",
    "The granularity of the data collection, which is approximately every 10 minutes during active enrollment periods, offers in depth insight into enrollment patterns, though for the purpose of our analysis, we will be implementing a more manageable sampling frequency. \n",
    "\n",
    "### Data Quality and Completeness\n",
    "\n",
    "The dataset encompasses all undergraduate courses offered at UC San Diego across eleven quarters, providing a comprehensive view of enrollment patterns. While the number of observations varies between courses and quarters—primarily due to differences in course offerings and enrollment period durations — the consistency in variable recording ensures data compatibility across all terms.\n",
    "\n",
    "### Data Processing Considerations\n",
    "For our analysis, several key processing steps will be implemented:\n",
    "1. Temporal aggregation to reduce unnecessary granularity while maintaining ensuring the trend of the data is captured accurately\n",
    "2. Consistency of course codes to enable cross-quarter analysis\n",
    "3. Enrollment phase demarcations (first pass, second pass, waitlist periods)\n",
    "4. Creation of derived metrics such as fill rates to enhance analysis capabilities\n",
    "5. Assignment of class standings (First-Year, Sophomore, Junior, Senior) to reflect enrollment priority hierarchies.\n",
    "\n",
    "This dataset serves as an invaluable resource for understanding UC San Diego's enrollment patterns, offering insights that can inform both administrative decision-making and student course planning strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial approach to data collection from GitHub appeared straightforward, utilizing the pandas' read_csv() method to access the datasets hosted on GitHub. However, the extensive scope of the dataset—encompassing thousands of subjects with multiple observations across eleven academic quarters rendered this method inefficient, with projected data retrieval times exceeding twelve hours.\n",
    "\n",
    "To enhance performance, we implemented several optimization strategies. First, we employed the chunking mechanism within read_csv() to process data in segments. While this modification yielded some improvement in processing speed, the enhancement was marginal for our requirements. Furthermore, we encountered limitations imposed by GitHub's API rate restrictions.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1). \n",
    "\n",
    "To address these constraints, we implemented parallel processing using the concurrent.futures package, enabling simultaneous retrieval of multiple files. This significantly improved operational efficiency<a name=\"cite_ref-1\"></a><sup>1</sup>. Additionally, we found that GitHub's API authentication system offered substantially higher rate limits, 5,000 requests per hour, for authenticated users compared to 60 for unauthenticated users. Therefore we implementated authentication headers in our requests to effectively circumvent the restrictions.\n",
    "\n",
    "A subsequent challenge emerged regarding data completeness. Our initial API implementation for retrieving directory contents was subject to GitHub's truncation limit of 999 files per directory, resulting in incomplete data collection. Through further research, we identified that the git/trees API provided access to the complete file directory, including previously truncated entries. This solution ensured we collected complete data<a name=\"cite_ref-2\"></a><sup>2</sup>.\n",
    "\n",
    "To optimize computational efficiency and eliminate redundant processing, we stored the collected data in enrollment_data.csv. The presence of this file in the working directory enables the system to skip the data collection process during subsequent notebook kernel restarts.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) https://medium.com/@smrati.katiyar/introduction-to-concurrent-futures-in-python-009fe1d4592c\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) https://docs.github.com/en/rest/repos/contents?apiVersion=2022-11-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the repo-links that host the data for each quarter in a csv file\n",
    "repo_links = [\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2022Fall/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2023Winter/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2023Spring/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2023Fall/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2024Winter/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2024Spring/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2024Summer1/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2024Summer2/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2024Summer3/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2024Fall/contents/overall',\n",
    "    'https://api.github.com/repos/UCSD-Historical-Enrollment-Data/2025Winter/contents/overall',\n",
    "      ]\n",
    "\n",
    "quarter_names = ['FA 22','WI 23', 'SP 23', 'FA 23', 'WI 24', 'SP 24', 'S1 24', 'S2 24', 'S3 24', 'FA 24', 'WI 25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# github token for adressing the limit on github api rates. \n",
    "# recommended to create an environment varaible to store this for improved security. Alternatively, one can simply add the github token below\n",
    "GITHUB_TOKEN = 'put in your token'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check if the new enrollment data file already exists\n",
    "if os.path.exists('enrollment_data.csv'):\n",
    "    df = pd.read_csv('enrollment_data.csv') \n",
    "else:\n",
    "    # this function processes the data quarter by quarter\n",
    "    def process_quarter(repo_link, quarter_name):\n",
    "        # try-except block to handle errors\n",
    "        try:\n",
    "            # extract repo name from the API URL\n",
    "            repo_name = repo_link.split('/')[5]  \n",
    "            \n",
    "            # construct tree API URL to gett all the files that are hidden as well\n",
    "            tree_url = f\"https://api.github.com/repos/UCSD-Historical-Enrollment-Data/{repo_name}/git/trees/main?recursive=1\"\n",
    "            \n",
    "            # add headers to account for GitHub API rate limiting\n",
    "            headers = {\n",
    "                'Accept': 'application/vnd.github.v3+json',\n",
    "                'Authorization': f'token {GITHUB_TOKEN}'\n",
    "            }\n",
    "            \n",
    "            # get the tree\n",
    "            response = requests.get(tree_url, headers=headers)\n",
    "            \n",
    "            # if request was unsuccessful print error message\n",
    "            if response.status_code != 200:\n",
    "                print(f\"failed to access {tree_url}\")\n",
    "                print(f\"Response: {response.text}\")\n",
    "                return None\n",
    "                \n",
    "            # get all files from the 'overall' directory\n",
    "            all_files = [item['path'].split('/')[-1] \n",
    "                        for item in response.json()['tree'] \n",
    "                        if item['path'].startswith('overall/') and item['path'].endswith('.csv')]\n",
    "                        \n",
    "            # process multiple files in parallel to make the process faster and more efficient\n",
    "            dfs = []\n",
    "            with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "                # create a list of futures where each future represents a file being processed\n",
    "                futures = [executor.submit(process_file, file, repo_name, quarter_name) \n",
    "                        for file in all_files]\n",
    "                \n",
    "                # loop through completed futures and collect results\n",
    "                for future in futures:  \n",
    "                    try:\n",
    "                        df = future.result()\n",
    "                        if df is not None:\n",
    "                            dfs.append(df)\n",
    "                    except Exception as e:\n",
    "                        # print error in case of an error\n",
    "                        print(f\"error in future: {str(e)}\")\n",
    "            \n",
    "            # if dfs is not empty, concatenate all the dfs for that quarter and return that\n",
    "            if dfs:\n",
    "                return pd.concat(dfs, ignore_index=True)\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print error msg if it occurs\n",
    "            print(f\"error processing quarter {quarter_name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    # function that reads the csv file and makes it into a df\n",
    "    def process_file(file, repo_name, quarter_name):\n",
    "        print(file)\n",
    "        # try-except block to handle errors\n",
    "        try:\n",
    "            # convert file name to the format seen in the url\n",
    "            file_url = file.replace(' ','%20')\n",
    "            \n",
    "            # raw csv file link\n",
    "            raw_url = f\"https://raw.githubusercontent.com/UCSD-Historical-Enrollment-Data/{repo_name}/main/overall/{file_url}\"\n",
    "            \n",
    "            # add authentication headers\n",
    "            headers = {\n",
    "                'Accept': 'application/vnd.github.v3+json',\n",
    "                'Authorization': f'token {GITHUB_TOKEN}'\n",
    "            }\n",
    "            \n",
    "            # Read the csv files with authentication\n",
    "            response = requests.get(raw_url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # read csv file into a pandas df\n",
    "            df = pd.read_csv(\n",
    "                io.StringIO(response.text),\n",
    "                sep=',',              # the separator\n",
    "                encoding='utf-8',     # specify the character encoding\n",
    "                parse_dates=['time'], # parse dates as datetime objects as they are being read to save time\n",
    "                usecols=['time', 'enrolled', 'available', 'waitlisted', 'total'] # specify column names to improve efficiency\n",
    "            )\n",
    "            \n",
    "            if not df.empty:\n",
    "                # add course column that is readable\n",
    "                df['course'] = file.replace('.csv', '').replace('%20',' ')\n",
    "                # group df at a frequency of every 12 hrs to get 2 readings for each day\n",
    "                df = df.groupby(pd.Grouper(key='time', freq='12h')).first().reset_index()\n",
    "                # add a column that stores the quarter name\n",
    "                df['quarter'] = quarter_name\n",
    "                return df\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            # if there is an error, print it\n",
    "            print(f\"error processing {file}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def load_data():\n",
    "        # list that will store the df for every quarter\n",
    "        all_quarter_dfs = []\n",
    "\n",
    "        # loop through each quarter and process its data\n",
    "        for repo_link, quarter_name in zip(repo_links, quarter_names):  \n",
    "            # delay to avoid hitting githubs rate limits\n",
    "            if all_quarter_dfs:\n",
    "                time.sleep(5)\n",
    "\n",
    "            # process the current quarters data   \n",
    "            quarter_df = process_quarter(repo_link, quarter_name)\n",
    "\n",
    "            # append data to all_quarter_dfs if df is not empty\n",
    "            if quarter_df is not None:\n",
    "                all_quarter_dfs.append(quarter_df)\n",
    "                \n",
    "                # save progress after each quarter in case the program crashes            \n",
    "                temp_df = pd.concat(all_quarter_dfs, ignore_index=True)\n",
    "                temp_df.to_csv('enrollment_data_temp.csv', \n",
    "                            index=False,\n",
    "                            encoding='utf-8')\n",
    "        \n",
    "        # save the final complete dataset\n",
    "        if all_quarter_dfs:\n",
    "            combined_df = pd.concat(all_quarter_dfs, ignore_index=True)\n",
    "            combined_df.to_csv('enrollment_data.csv', \n",
    "                            index=False,\n",
    "                            encoding='utf-8')\n",
    "            return combined_df\n",
    "        return None\n",
    "\n",
    "    # run the load_data function\n",
    "    df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file created by the function load_data() was too large to upload onto GitHub (more than 150 mb) hence we uploaded it to google drive. \n",
    "\n",
    "The raw data we collected can be found here: https://drive.google.com/file/d/1Xv0GoHwTJ19rF9oBCIs7jF0etkzkJPhy/view?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>available</th>\n",
       "      <th>waitlisted</th>\n",
       "      <th>total</th>\n",
       "      <th>course</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-18 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-18 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-19 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-19 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-20 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070123</th>\n",
       "      <td>2025-01-25 00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WES 269</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070124</th>\n",
       "      <td>2025-01-25 12:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WES 269</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070125</th>\n",
       "      <td>2025-01-26 00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WES 269</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070126</th>\n",
       "      <td>2025-01-31 00:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WES 269</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070127</th>\n",
       "      <td>2025-01-31 12:00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>WES 269</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3070128 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  enrolled  available  waitlisted  total   course  \\\n",
       "0        2022-05-18 00:00:00       0.0       68.0         0.0   68.0   AAS 10   \n",
       "1        2022-05-18 12:00:00       0.0       68.0         0.0   68.0   AAS 10   \n",
       "2        2022-05-19 00:00:00       0.0       68.0         0.0   68.0   AAS 10   \n",
       "3        2022-05-19 12:00:00       0.0       68.0         0.0   68.0   AAS 10   \n",
       "4        2022-05-20 00:00:00       0.0       68.0         0.0   68.0   AAS 10   \n",
       "...                      ...       ...        ...         ...    ...      ...   \n",
       "3070123  2025-01-25 00:00:00       8.0        7.0         0.0   15.0  WES 269   \n",
       "3070124  2025-01-25 12:00:00       8.0        7.0         0.0   15.0  WES 269   \n",
       "3070125  2025-01-26 00:00:00       8.0        7.0         0.0   15.0  WES 269   \n",
       "3070126  2025-01-31 00:00:00       8.0        7.0         0.0   15.0  WES 269   \n",
       "3070127  2025-01-31 12:00:00       8.0        7.0         0.0   15.0  WES 269   \n",
       "\n",
       "        quarter  \n",
       "0         FA 22  \n",
       "1         FA 22  \n",
       "2         FA 22  \n",
       "3         FA 22  \n",
       "4         FA 22  \n",
       "...         ...  \n",
       "3070123   WI 25  \n",
       "3070124   WI 25  \n",
       "3070125   WI 25  \n",
       "3070126   WI 25  \n",
       "3070127   WI 25  \n",
       "\n",
       "[3070128 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see if we have any missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          0\n",
       "enrolled      0\n",
       "available     0\n",
       "waitlisted    0\n",
       "total         0\n",
       "course        0\n",
       "quarter       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to ensure that all columns are of the right data type and consistently formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting 'time' column to datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# converting 'enrolled', 'available', 'waitlisted', and 'total' columns to float (easier to handle)\n",
    "df['enrolled'] = df['enrolled'].astype(float)\n",
    "df['available'] = df['available'].astype(float)\n",
    "df['waitlisted'] = df['waitlisted'].astype(float)\n",
    "df['total'] = df['total'].astype(float)\n",
    "\n",
    "# converting 'course' and 'quarter' columns to strings\n",
    "df['course'] = df['course'].astype(str)\n",
    "df['quarter'] = df['quarter'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time          datetime64[ns]\n",
       "enrolled             float64\n",
       "available            float64\n",
       "waitlisted           float64\n",
       "total                float64\n",
       "course                object\n",
       "quarter               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all columns are correctly formatted in the appropriate data types.\n",
    "\n",
    "While observing our raw data, we realized that there were some graduate level courses included in this datasets. Since our analysis focuses primarily on undergraduate enrollment, we will be working solely with undergraduate course and exclude all graduate courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>available</th>\n",
       "      <th>waitlisted</th>\n",
       "      <th>total</th>\n",
       "      <th>course</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-18 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-18 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-19 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-19 12:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-20 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069658</th>\n",
       "      <td>2025-01-25 00:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069659</th>\n",
       "      <td>2025-01-25 12:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069660</th>\n",
       "      <td>2025-01-26 00:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069661</th>\n",
       "      <td>2025-01-31 00:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069662</th>\n",
       "      <td>2025-01-31 12:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2278752 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  enrolled  available  waitlisted  total    course  \\\n",
       "0       2022-05-18 00:00:00       0.0       68.0         0.0   68.0    AAS 10   \n",
       "1       2022-05-18 12:00:00       0.0       68.0         0.0   68.0    AAS 10   \n",
       "2       2022-05-19 00:00:00       0.0       68.0         0.0   68.0    AAS 10   \n",
       "3       2022-05-19 12:00:00       0.0       68.0         0.0   68.0    AAS 10   \n",
       "4       2022-05-20 00:00:00       0.0       68.0         0.0   68.0    AAS 10   \n",
       "...                     ...       ...        ...         ...    ...       ...   \n",
       "3069658 2025-01-25 00:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069659 2025-01-25 12:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069660 2025-01-26 00:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069661 2025-01-31 00:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069662 2025-01-31 12:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "\n",
       "        quarter  \n",
       "0         FA 22  \n",
       "1         FA 22  \n",
       "2         FA 22  \n",
       "3         FA 22  \n",
       "4         FA 22  \n",
       "...         ...  \n",
       "3069658   WI 25  \n",
       "3069659   WI 25  \n",
       "3069660   WI 25  \n",
       "3069661   WI 25  \n",
       "3069662   WI 25  \n",
       "\n",
       "[2278752 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the course number and convert to integer\n",
    "df['course_number'] = df['course'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# filter out graduate courses where the number is >=200\n",
    "df = df[df['course_number'] < 200]\n",
    "\n",
    "# drop the temporary course_number column \n",
    "df = df.drop('course_number', axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract further information, we need to know when registration opens for each quarter.\n",
    "\n",
    "In order to do this, we will scrape UCSD's publically available yearly \"enrollment and registration calendars\" to determine the first day of enrollment for each quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FA 22': '5/20/22',\n",
       " 'WI 23': '11/7/22',\n",
       " 'SP 23': '2/18/23',\n",
       " 'FA 23': '5/26/23',\n",
       " 'WI 24': '11/14/23',\n",
       " 'SP 24': '2/17/24',\n",
       " 'S1 24': '4/15/24',\n",
       " 'S2 24': '4/15/24',\n",
       " 'S3 24': '4/15/24',\n",
       " 'FA 24': '5/24/24',\n",
       " 'WI 25': '11/12/24'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_links = [\n",
    "    'https://blink.ucsd.edu/instructors/courses/enrollment/calendars/2022.html',    # 2022 - 2023\n",
    "    'https://blink.ucsd.edu/instructors/courses/enrollment/calendars/2023.html',    # 2023 - 2024\n",
    "    'https://blink.ucsd.edu/instructors/courses/enrollment/calendars/2024.html'     # 2024 - 2025\n",
    "]\n",
    "\n",
    "def process_calendar(link, yr):\n",
    "    r = requests.get(link)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "    # The website has a table with every important date\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # Store enrollment start dates w/ same formatting as the 'quarter' column of the df\n",
    "    dates = {}\n",
    "\n",
    "    # Iterate through table rows\n",
    "    for row in table.find_all('tr'): \n",
    "        cells = row.find_all('td')\n",
    "        if cells:\n",
    "            label = cells[0].get_text(strip=True)\n",
    "            if 'Enrollment begins' in label:\n",
    "                dates['FA' + \" \" + str(yr)] = cells[1].get_text(strip=True) + \"/\" + str(yr)\n",
    "\n",
    "                s = str(yr + 1)\n",
    "                dates['WI' + \" \" + s] = cells[2].get_text(strip=True) + \"/\" + str(yr)\n",
    "\n",
    "                if yr < 24: \n",
    "                    dates['SP' + \" \" + s] = cells[3].get_text(strip=True) + \"/\" + s\n",
    "\n",
    "                if yr == 23:\n",
    "                    dates['S1' + \" \" + s] = cells[4].get_text(strip=True) + \"/\" + s\n",
    "                    dates['S2' + \" \" + s] = cells[4].get_text(strip=True) + \"/\" + s\n",
    "                    dates['S3' + \" \" + s] = cells[4].get_text(strip=True) + \"/\" + s\n",
    "                break\n",
    "    return dates\n",
    "\n",
    "enrollment_starts = {}\n",
    "year = 22\n",
    "for link in calendar_links:\n",
    "    enrollment_starts.update(process_calendar(link, year))\n",
    "    year += 1\n",
    "enrollment_starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the month/day/year format into a datetime object for consistent formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FA 22': Timestamp('2022-05-20 00:00:00'),\n",
       " 'WI 23': Timestamp('2022-11-07 00:00:00'),\n",
       " 'SP 23': Timestamp('2023-02-18 00:00:00'),\n",
       " 'FA 23': Timestamp('2023-05-26 00:00:00'),\n",
       " 'WI 24': Timestamp('2023-11-14 00:00:00'),\n",
       " 'SP 24': Timestamp('2024-02-17 00:00:00'),\n",
       " 'S1 24': Timestamp('2024-04-15 00:00:00'),\n",
       " 'S2 24': Timestamp('2024-04-15 00:00:00'),\n",
       " 'S3 24': Timestamp('2024-04-15 00:00:00'),\n",
       " 'FA 24': Timestamp('2024-05-24 00:00:00'),\n",
       " 'WI 25': Timestamp('2024-11-12 00:00:00')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in enrollment_starts:\n",
    "    enrollment_starts[key] = pd.to_datetime(enrollment_starts[key], format='%m/%d/%y')\n",
    "\n",
    "enrollment_starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the following task.\n",
    "\n",
    "- The dataset contains datapoints from before the enrollment period opens. This may skew the data, making it appear as if open slots are available for longer than they actually are.\n",
    "- We will remove these datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>available</th>\n",
       "      <th>waitlisted</th>\n",
       "      <th>total</th>\n",
       "      <th>course</th>\n",
       "      <th>quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-20 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-05-20 12:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-05-21 00:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-05-21 12:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-05-22 00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>AAS 10</td>\n",
       "      <td>FA 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069658</th>\n",
       "      <td>2025-01-25 00:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069659</th>\n",
       "      <td>2025-01-25 12:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069660</th>\n",
       "      <td>2025-01-26 00:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069661</th>\n",
       "      <td>2025-01-31 00:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069662</th>\n",
       "      <td>2025-01-31 12:00:00</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>WCWP 10B</td>\n",
       "      <td>WI 25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2206804 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time  enrolled  available  waitlisted  total    course  \\\n",
       "4       2022-05-20 00:00:00       0.0       68.0         0.0   68.0    AAS 10   \n",
       "5       2022-05-20 12:00:00       1.0       67.0         0.0   68.0    AAS 10   \n",
       "6       2022-05-21 00:00:00       3.0       65.0         0.0   68.0    AAS 10   \n",
       "7       2022-05-21 12:00:00       5.0       63.0         0.0   68.0    AAS 10   \n",
       "8       2022-05-22 00:00:00       6.0       62.0         0.0   68.0    AAS 10   \n",
       "...                     ...       ...        ...         ...    ...       ...   \n",
       "3069658 2025-01-25 00:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069659 2025-01-25 12:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069660 2025-01-26 00:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069661 2025-01-31 00:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "3069662 2025-01-31 12:00:00     319.0        1.0        12.0  320.0  WCWP 10B   \n",
       "\n",
       "        quarter  \n",
       "4         FA 22  \n",
       "5         FA 22  \n",
       "6         FA 22  \n",
       "7         FA 22  \n",
       "8         FA 22  \n",
       "...         ...  \n",
       "3069658   WI 25  \n",
       "3069659   WI 25  \n",
       "3069660   WI 25  \n",
       "3069661   WI 25  \n",
       "3069662   WI 25  \n",
       "\n",
       "[2206804 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['quarter'].map(enrollment_starts) <= df['time']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quarter\n",
       "FA 24    406836\n",
       "FA 22    358434\n",
       "FA 23    318676\n",
       "WI 23    243772\n",
       "WI 24    233293\n",
       "SP 23    206777\n",
       "SP 24    192047\n",
       "WI 25    188815\n",
       "S1 24     37034\n",
       "S2 24     19261\n",
       "S3 24      1859\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quarter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need columns that measure enrollment priority (senior, junior...) and pass # (1, 2), as these are integral parts of our research question. These can easily be derived with respect to each quarter's enrollment start date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enrollment start dates for incoming students\n",
    "fa_fresh_start = {\n",
    "    'FA 22' : pd.to_datetime(\"8-17-2022\"),\n",
    "    'FA 23' : pd.to_datetime(\"8-28-2023\"),\n",
    "    'FA 24' : pd.to_datetime(\"8-12-2024\")\n",
    "}\n",
    "\n",
    "def registration_priority(date, quarter):\n",
    "\n",
    "    # Ensure consistent formatting \n",
    "    enrollment_start_date = pd.to_datetime(enrollment_starts[quarter])\n",
    "    date = pd.to_datetime(date)\n",
    "    days = int((date - enrollment_start_date).days) # number of days since enrollment has been open\n",
    "    \n",
    "    pass_num = 0   \n",
    "    priority = 0 \n",
    "\n",
    "    # first week of registration is first pass                               \n",
    "    if 0 <= days and days < 7:\n",
    "        pass_num = 1            \n",
    "        if days == 0:\n",
    "            priority = 1    # first day of each pass is senior enrollment (1)\n",
    "        elif days == 1:\n",
    "            priority = 2    # second day = junior (2)\n",
    "        elif days == 2: \n",
    "            priority = 3    # soph (3)\n",
    "        else:\n",
    "            priority = 4    # fresh (4)\n",
    "\n",
    "    # second week is second pass\n",
    "    elif 7 <= days and days < 14:\n",
    "        pass_num = 2 \n",
    "        if days == 7:\n",
    "            priority = 1\n",
    "        elif days == 8:\n",
    "            priority = 2\n",
    "        elif days == 9:\n",
    "            priority = 3\n",
    "        else:\n",
    "            priority = 4 \n",
    "\n",
    "    # afterwards, registration is open to all\n",
    "    else:\n",
    "        # these values are just placeholders to represent that anybody can enroll\n",
    "        pass_num = 3 \n",
    "        priority = 6        \n",
    "\n",
    "    # Incoming freshman enrollment is unique\n",
    "    if 'FA' in quarter:\n",
    "        days = int((date - fa_fresh_start[quarter]).days)\n",
    "        \n",
    "        if 0 <= days and days < 7:\n",
    "            pass_num = 1\n",
    "            priority = 5\n",
    "        elif 7 <= days and days < 14:\n",
    "            pass_num = 2\n",
    "            priority = 5\n",
    "    \n",
    "    return pass_num, priority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "    df[['pass', 'priority']] = df.apply(lambda row: registration_priority(row['time'], row['quarter']), axis=1, result_type='expand')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['priority'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the value counts that certain subsets are over-represented. It simply doesn't make sense to have so much data outside of first and second pass, when these are the focus of our question.\n",
    "\n",
    "1. There is a disproportionate number of days of freshman priority (4). This is because we're considering all days after sophomore enrollment, but before the end of the week, to be freshman enrollment.\n",
    "\n",
    "2. The same is true for incoming freshman enrollment (priorty 5).\n",
    "\n",
    "3. The same is true for when enrollment is opened to all students (priority 6).\n",
    "\n",
    "Realistically, we only need to know how many seats are available during the first day of someone's first pass, first day of their second pass, and first day of open enrollment. Anything beyond this will simply skew our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first date for each group\n",
    "first_dates = df.groupby(['quarter', 'pass', 'priority'])['time'].min().reset_index()\n",
    "\n",
    "# Merge with the original df to keep all unique (quarter, pass, priority) entries on the first date\n",
    "df = pd.merge(df, first_dates, on=['quarter', 'pass', 'priority', 'time'], how='inner')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['priority'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much more representative of the analysis we want to do, which prioritizes senior to freshman registration during first and second pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('new_enrollment_data.csv'):\n",
    "    df.to_csv('new_enrollment_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Lastly, we need to create a column that keeps track of the proportion of total seats that have been filled for each course, as this is also an integral part of our research question and could prove very useful in our analysis when observing trends in how quickly a class fills up. \n",
    "\n",
    "To do that, we will create a new column 'fill rate' that computes the proportion of filled seats as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding fill rate column\n",
    "df[\"fill rate\"] = df['enrolled'] / df['total']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a lot of missing values generated by the 'fill rate' column. Digging a little deeper, it seems that there are some observations in our dataset, as you can see below, where the total number of seats for the course is listed as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# courses with 0 total seats\n",
    "df[df['total'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More surprisingly, a lot of these courses have values greater than 0 in the 'enrolled' and 'waitlisted' columns. This could be some sort of error on the webscraping process used to fetch data, or possibly an error on UCSD's course registration portal.\n",
    "\n",
    "As a result, our calculation of fill rate must handle these values appropriately to avoid running into zero division errors and missing values. To do this, we created a helper function that fills in 0 for 'fill rate' in rows where 'total' is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fill_rate(row):\n",
    "    # to avoid zero division errors\n",
    "    if not row['total']:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return row['enrolled'] / row['total']\n",
    "\n",
    "\n",
    "df[\"fill rate\"] = df.apply(get_fill_rate, axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed with our analysis, we need to ensure that there are no other unusual or unnecessary data.\n",
    "\n",
    "We can check this by getting some descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the maximum values for 'available' and 'total' columns, it seems like there are some courses in our dataset where the total number of seats are over 280,000!\n",
    "\n",
    "Generally, it is unlikely that there are courses with over 1000 seats, so these data points are likely outliers. As a result, we wil remove these rows from our dataset and only consider courses that have under 1000 seats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['total'] < 1000]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also ensure that the fill rate column has values that are appropriate (i.e. values range between 0 and 1), and remove the rows that have values outside that range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows with fill rate outside of range(0, 1)\n",
    "df = df[(df['fill rate'] > 0) & (df['fill rate'] <= 1.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is now finally ready to be used to carry out descriptive and exploratory analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it would be useful to generate some exploratory visualizations to help observe trends in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = pd.plotting.scatter_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the visualizations above that the columns 'enrolled', 'available', 'waitlisted', and 'total' exhibit a linear relationship, as one would expect.\n",
    "\n",
    "Let's explore the distributions of some of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# distribution of total seats\n",
    "sns.histplot(x='total', bins=30, kde=True, data=df, ax=axes[0])\n",
    "axes[0].set_title(\"Total Seats Distribution\")\n",
    "\n",
    "# distribution of enrolled seats\n",
    "sns.histplot(x='enrolled', bins=30, kde=True, data=df, ax=axes[1])\n",
    "axes[1].set_title(\"Enrolled Students Distribution\")\n",
    "\n",
    "# distribution of available seats\n",
    "sns.histplot(x='available', bins=30, kde=True, data=df, ax=axes[2])\n",
    "axes[2].set_title(\"Available Seats Distribution\")\n",
    "\n",
    "# distribution of waitlisted seats\n",
    "sns.histplot(x='waitlisted', bins=30, kde=True, data=df, ax=axes[3])\n",
    "axes[3].set_title(\"Waitlisted Seats Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# distribution of total seats by quarter\n",
    "sns.boxplot(x=\"quarter\", y=\"total\", data=df, ax=axes[0])\n",
    "axes[0].set_xlabel(\"Quarter\")\n",
    "axes[0].set_ylabel(\"Total Seats\")\n",
    "axes[0].set_title(\"Total Seats Distribution by Quarter\")\n",
    "\n",
    "# distribution of enrolled seats by quarter\n",
    "sns.boxplot(x=\"quarter\", y=\"enrolled\", data=df, ax=axes[1])\n",
    "axes[1].set_xlabel(\"Quarter\")\n",
    "axes[1].set_ylabel(\"Enrolled Seats\")\n",
    "axes[1].set_title(\"Enrolled Seats Distribution by Quarter\")\n",
    "\n",
    "# distribution of available seats by quarter\n",
    "sns.boxplot(x=\"quarter\", y=\"available\", data=df, ax=axes[2])\n",
    "axes[2].set_xlabel(\"Quarter\")\n",
    "axes[2].set_ylabel(\"Available Seats\")\n",
    "axes[2].set_title(\"Available Seats Distribution by Quarter\")\n",
    "\n",
    "# distribution of waitlisted seats by quarter\n",
    "sns.boxplot(x=\"quarter\", y=\"waitlisted\", data=df, ax=axes[3])\n",
    "axes[3].set_xlabel(\"Quarter\")\n",
    "axes[3].set_ylabel(\"Waitlisted Seats\")\n",
    "axes[3].set_title(\"Waitlisted Seats Distribution by Quarter\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram plots of these columns, it can be clearly seen that the distributions are all right-skewed. This is not surprising, as most class sizes are typically less than 300 as seen from the box plots above.\n",
    "\n",
    "Let's also plot the distribution of fill rates to see if any interesting patterns emerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# distribution of fill rate\n",
    "sns.histplot(x=\"fill rate\", bins=30, kde=True, data=df, ax=axes[0])\n",
    "axes[0].set_xlabel(\"Fill Rate\")\n",
    "axes[0].set_ylabel(\"Frequency\")\n",
    "axes[0].set_title(\"Distribution of Fill Rate\")\n",
    "\n",
    "sns.boxplot(x=\"quarter\", y=\"fill rate\", data=df, ax=axes[1])\n",
    "axes[1].set_xlabel(\"Quarter\")\n",
    "axes[1].set_ylabel(\"Fill Rate\")\n",
    "axes[1].set_title(\"Fill Rate Distribution by Quarter\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the number of available seats by our variables of interest: pass and priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# number of available seats by pass\n",
    "sns.barplot(x=\"pass\", y=\"available\", data=df, ax=axes[0])\n",
    "axes[0].set_xlabel(\"Pass\")\n",
    "axes[0].set_ylabel(\"Available Seats\")\n",
    "axes[0].set_title(\"Available Seats by Pass\")\n",
    "\n",
    "# number of available seats vs. priority\n",
    "sns.barplot(x=\"priority\", y=\"available\", data=df, ax=axes[1])\n",
    "axes[1].set_xlabel(\"Enrollment Priority\")\n",
    "axes[1].set_ylabel(\"Available Seats\")\n",
    "axes[1].set_title(\"Available Seats vs. Priority\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of available seats seems to be decrease with later passes, which is consistent with our expectations. The number of available seats also follows a similar trend. However, there seems to be fewer available seats for seniors than juniors, which is surprising. There are possibly numerous reasons for this, some of which include delays in accurately entering the number of seats for a course on the first day of first pass.\n",
    "\n",
    "Next, let's look at the distribution of courses across departments, starting with the number of courses offered by each department and computing the top ten most enrolled courses overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depts = pd.Series(df[\"course\"].unique()).str.split().str[0]\n",
    "\n",
    "# Count the number of courses per department\n",
    "dept_counts = depts.value_counts()\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(12, 24))\n",
    "sns.barplot(y=dept_counts.index, x=dept_counts.values)\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel(\"Department\", fontsize=12)\n",
    "plt.xlabel(\"Number of Courses\", fontsize=12)\n",
    "plt.title(\"Number of Courses in Each Department\", fontsize=14)\n",
    "plt.xticks(rotation=45)  # Rotate for readability\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute the mean fill rate for each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top ten most enrolled courses\n",
    "top_courses = df.groupby(\"course\")[\"enrolled\"].max().nlargest(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=top_courses.values, y=top_courses.index)\n",
    "plt.xlabel(\"Max Enrollment\")\n",
    "plt.ylabel(\"Course\")\n",
    "plt.title(\"Top 10 Most Enrolled Courses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['department'] = df[\"course\"].str.split().str[0]\n",
    "df\n",
    "\n",
    "avg_fill_rate_by_dept = df.groupby('department')['fill rate'].median()\n",
    "avg_fill_rate_by_dept\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(12, 24))\n",
    "sns.barplot(y=avg_fill_rate_by_dept.index, x=avg_fill_rate_by_dept.sort_values(ascending=False))\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel(\"Department\", fontsize=12)\n",
    "plt.xlabel(\"Median fill rate\", fontsize=12)\n",
    "plt.title(\"Median Fill Rate by Department\", fontsize=14)\n",
    "plt.xticks(rotation=45)  # Rotate for readability\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above shows in descending order the median fill rates by departments. This gives us an insight into how 'full' certain departments are over others which will be important for predicting which classes should be taken during first pass, second pass, and third pass respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below allows you to explore the trend in the number of available seats over the course of first, second, and third pass for any given course in a specific quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_name = \"MATH 181A\"  # Change to the course you want\n",
    "quarter_name = \"WI 25\"  # Change to the quarter you want\n",
    "\n",
    "# Filter the dataframe for the specific course and quarter\n",
    "df_filtered = df[(df[\"course\"] == course_name) & (df[\"quarter\"] == quarter_name)]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_filtered, x=\"time\", y=\"available\", hue=\"pass\", palette=\"viridis\", s=100, alpha=0.7)\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Available Seats\")\n",
    "plt.title(f\"Available Seats vs. Capacity for {course_name} ({quarter_name})\")\n",
    "plt.legend(title=\"Pass\")  # Legend for first-pass vs. second-pass\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at `fill rate` and its effect on seat `availability` as it can be used to help determine the effect of other variables. If there is a strong correlation, a strong effect on fill rate from other variables will also mean a strong effect on seat availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate df so we can look specifically into first and second pass\n",
    "df_first = df[df['pass'] == 1]\n",
    "df_second = df[df['pass'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create bins for a cleaner plot\n",
    "bins = [0, 100, 200, 400, 600, 800, 1000]\n",
    "labels = [\"0-100\", \"<200\", \"<400\", \"<600\", \"<800\", \"<1000\"]\n",
    "df[\"available_bin\"] = pd.cut(df[\"available\"], bins=bins, labels=labels)\n",
    "\n",
    "# Create color gradient\n",
    "colors = list(reversed(sns.color_palette(\"Purples\", len(labels))))\n",
    "\n",
    "# Create subplots (so plots are side by side)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Create box plot for first pass\n",
    "sns.boxplot(x=df[\"available_bin\"], y=df_first[\"fill rate\"], palette=colors, ax=axes[0])\n",
    "\n",
    "# Create box plot for second pass\n",
    "sns.boxplot(x=df[\"available_bin\"], y=df_second[\"fill rate\"], palette=colors, ax=axes[1])\n",
    "\n",
    "# Customize labels\n",
    "axes[0].set_xlabel(\"Availability (Binned)\")\n",
    "axes[0].set_ylabel(\"Fill Rate\")\n",
    "axes[0].set_title(\"Box Plot of Fill Rate by Availability Bins (First Pass)\")\n",
    "\n",
    "axes[1].set_xlabel(\"Availability (Binned)\")\n",
    "axes[1].set_ylabel(\"Fill Rate\")\n",
    "axes[1].set_title(\"Box Plot of Fill Rate by Availability Bins (Second Pass)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation between available seats and fill rate during first pass\n",
    "corr_1, p_val_1 = stats.pearsonr(df_first['available'], df_first['fill rate'])\n",
    "print(f\"Pearson Correlation: {corr_1}, p-value: {p_val_1}\")\n",
    "\n",
    "# Calculate Pearson correlation between available seats and fill rate during second pass\n",
    "corr_2, p_val_2 = stats.pearsonr(df_second['available'], df_second['fill rate'])\n",
    "print(f\"Pearson Correlation: {corr_2}, p-value: {p_val_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these box plots, we can observe that for both first and second pass, higher fill rates tend to lead to fewer available seats. The calculated Pearson correlation confirms this as we get a p-value that is so small that it returns as 0, indicating that there is a very strong negative correlation between available seats and fill rate. Also notice how first pass tends to have lower fill rates than second pass. This suggests that not all courses reach high fill rates immediately and that there are generally more open seats during first pass. By the time second pass occurs, more students have registered, leading to an overall increase in median fill rates. In other words, it is more difficult to find available seats during second pass, so it would be advised to secure more desired courses during first pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is such a significant correlation, we can now compare `fill rate` to course `capacity`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already intuitively know that a larger capacity will mean that there will be more seats. For example, a course with a capacity of 20 will already have fewer seats than a course with a capacity of 200. This doesn't necessarily mean that it determines how difficult it will be to secure a seat though. There could be a difference in demand that makes the course of 200 capacity fill up faster (have a high fill rate), and thus having fewer available seats, than the course of 20 capacity which barely fills up at all (low fill rate). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for a cleaner plot\n",
    "bins = [0, 100, 200, 400, 600, 800, 1000]\n",
    "labels = [\"0-100\", \"<200\", \"<400\", \"<600\", \"<800\", \"<1000\"]\n",
    "df_first[\"capacity_bin\"] = pd.cut(df_first[\"total\"], bins=bins, labels=labels)\n",
    "df_second[\"capacity_bin\"] = pd.cut(df_second[\"total\"], bins=bins, labels=labels)\n",
    "\n",
    "# Create color gradient\n",
    "colors = list(reversed(sns.color_palette(\"Blues\", len(labels))))\n",
    "\n",
    "# Create subplots (so plots are side by side)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Create box plot for first pass\n",
    "sns.boxplot(x=df_first[\"capacity_bin\"], y=df_first[\"fill rate\"], palette=colors, ax=axes[0])\n",
    "\n",
    "# Create box plot for first pass\n",
    "sns.boxplot(x=df_second[\"capacity_bin\"], y=df_second[\"fill rate\"], palette=colors, ax=axes[1])\n",
    "\n",
    "# Customize labels\n",
    "axes[0].set_xlabel(\"Course Capacity (Binned)\")\n",
    "axes[0].set_ylabel(\"Fill Rate\")\n",
    "axes[0].set_title(\"Box Plot of Fill Rate by Capacity Bins (First Pass)\")\n",
    "\n",
    "axes[1].set_xlabel(\"Course Capacity (Binned)\")\n",
    "axes[1].set_ylabel(\"Fill Rate\")\n",
    "axes[1].set_title(\"Box Plot of Fill Rate by Capacity Bins (Second Pass)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Pearson correlation between capacity and fill rate during first pass\n",
    "corr_1, p_val_1 = stats.pearsonr(df_first['total'], df_first['fill rate'])\n",
    "print(f\"First pass:\")\n",
    "print(f\"Pearson Correlation: {corr_1}, p-value: {p_val_1}\\n\")\n",
    "\n",
    "# Calculate Pearson correlation between capacity and fill rate during second pass\n",
    "corr_2, p_val_2 = stats.pearsonr(df_second['total'], df_second['fill rate'])\n",
    "print(f\"Second pass:\")\n",
    "print(f\"Pearson Correlation: {corr_2}, p-value: {p_val_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graphs above look into how fast courses of a different range of capacities fill up during first and second pass. From this, we observe two different kinds of relationships. For first pass, there is a negative significant correlation. For second pass, there is a positive significant correlation. The negative correlation suggests that courses with smaller capacities are in higher demand during first pass, therefore filling up faster, making it less likely to have available seats in those courses. The positive correlation suggests that after securing those smaller classes, students are now prioritizing larger course capacities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s analyze how enrollment counts differ across `priority` levels and `quarters`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group and count enrollments by priority and quarter\n",
    "enrollment_trends_1 = df_first.groupby(['priority', 'quarter']).size().unstack()\n",
    "enrollment_trends_2 = df_second.groupby(['priority', 'quarter']).size().unstack()\n",
    "\n",
    "# create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# plot results (first pass)\n",
    "enrollment_trends_1.plot(kind='bar', stacked=True, colormap='viridis', ax=axes[0])\n",
    "\n",
    "# plot results (second pass)\n",
    "enrollment_trends_2.plot(kind='bar', stacked=True, colormap='viridis', ax=axes[1])\n",
    "\n",
    "# labeling\n",
    "axes[0].set_title(\"Enrollment Trends by Priority and Quarter (First Pass)\")\n",
    "axes[0].set_xlabel(\"Priority Level\")\n",
    "axes[0].set_ylabel(\"Number of Enrollments\")\n",
    "\n",
    "axes[1].set_title(\"Enrollment Trends by Priority and Quarter (Second Pass)\")\n",
    "axes[1].set_xlabel(\"Priority Level\")\n",
    "axes[1].set_ylabel(\"Number of Enrollments\")\n",
    "\n",
    "plt.legend(title=\"Quarter\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The side-by-side bar charts above compare enrollment trends by `priority` level and `quarter` for first and second pass registrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the first pass, enrollment is predominantly concentrated among **higher priority levels (2–4)**, with **Priority Level 4** consistently showing the highest enrollments across all quarters. This reveals the significant advantage held by higher-priority students in securing courses early. Priority Level 1, in contrast, has notably lower enrollments during this phase, which may reflect limited access or a smaller cohort size. Among lower priority groups, Priority Level 5 exhibits moderate enrollment, though significantly trailing behind the higher priorities.\n",
    "\n",
    "In the second pass, the distribution becomes more balanced across higher priorities, as **Priority Levels 1, 2, 3, and 4** show comparable activity. However, **Priority Level 5** experiences a notable decline in enrollments during this phase, likely due to reduced course availability, reflecting the challenges faced by lower-priority groups in accessing courses.\n",
    "\n",
    "Seasonal trends are also evident across both passes, with **Fall quarters (FA 22, FA 23, FA 24)** consistently showing the highest enrollments. This highlights increased demand during the start of the academic year, as students register for core or foundational courses. Spring quarters (SP 23, SP 24) and Summer quarters (S1 24, S2 24, S3 24) display lower enrollments, suggesting decreased activity during these periods.\n",
    "\n",
    "These findings highlight the cyclical enrollment patterns shaped by the academic calendar, emphasizing the critical role of priority levels and registration phases in determining course accessibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having explored enrollment trends, we now shift to examine how fill rates vary across priority levels and quarters to observe key patterns in course utilization. To do this, the average fill rates were aggregated into a pivot table and visualized using heatmaps for both first and second pass registrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot tables for corresponding first pass and second pass heatmap\n",
    "pivot_1 = df_first.pivot_table(values=\"fill rate\", index=\"priority\", columns=\"quarter\", aggfunc=\"mean\")\n",
    "pivot_2 = df_second.pivot_table(values=\"fill rate\", index=\"priority\", columns=\"quarter\", aggfunc=\"mean\")\n",
    "\n",
    "# create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# generate heatmap for first pass\n",
    "sns.heatmap(pivot_1, ax=axes[0], cmap=\"YlGnBu\", annot=True, fmt=\".2f\")\n",
    "axes[0].set_title(\"Average Fill Rates by Priority and Quarter during First Pass\")\n",
    "axes[0].set_xlabel(\"Quarter\")\n",
    "axes[0].set_ylabel(\"Priority Level\")\n",
    "\n",
    "# generate heatmap\n",
    "sns.heatmap(pivot_2, ax=axes[1], cmap=\"YlGnBu\", annot=True, fmt=\".2f\")\n",
    "axes[1].set_title(\"Average Fill Rates by Priority and Quarter during Second Pass\")\n",
    "axes[1].set_xlabel(\"Quarter\")\n",
    "axes[1].set_ylabel(\"Priority Level\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmaps, we observe that **higher priority levels (1–4)** generally exhibit lower fill rates during the first pass, with averages ranging from approximately -0.7 to 0.4. This is expected, as higher-priority students typically register early when seats are more widely available. In contrast, **lower priority levels (5 and 6)** exhibit consistently higher fill rates, with averages between 0.4 and 0.8 during the second pass. This reflects these students' reliance on enrolling in high-demand courses that have already begun filling up.\n",
    "\n",
    "**Seasonal trends** are evident in the data. **Fall quarters (e.g., FA 22, FA 23, FA 24)** show relatively stable fill rates across all priority levels, indicating high demand for courses at the start of the academic year. In contrast, **Spring quarters (e.g., SP 23, SP 24)** and **Summer quarters (S1 24, S2 24, S3 24)** reveal greater variability. For example, Priority 4 in **S2 24** experiences a spike in fill rates, potentially due to increased demand or limited course availability. Conversely, Priority 1 in **S1 24** shows particularly low fill rates, which may suggest limited course offerings for this group.\n",
    "\n",
    "Additionally, the gap in fill rates between priority groups highlights disparities in course access. For instance, during the first pass, fill rates for Priority 5 rise sharply in certain quarters, like **FA 22**, while during the second pass, Priority 6 reaches the highest observed fill rates, such as **SP 23 (0.72)**. Meanwhile, higher-priority groups consistently exhibit lower fill rates, illustrating their advantage in accessing available courses during earlier registration phases.\n",
    "\n",
    "These findings illustrate the complex relationship between `priority` levels, registration passes, and seasonal patterns, shedding light on the inequities faced by lower-priority groups and offering critical insights for enhancing enrollment strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so now when it comes to assess whether the observed differences in average fill rates across priority levels are statistically significant, we perform a one-way Analysis of Variance (ANOVA). This test evaluates whether the mean fill rates differ significantly between the groups (`priority` levels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# group fill rates by priority (first pass)\n",
    "groups_priority = [group[\"fill rate\"] for _, group in df_first.groupby(\"priority\")]\n",
    "f_stat, p_value = f_oneway(*groups_priority)\n",
    "\n",
    "print(f\"ANOVA Test - F-Statistic: {f_stat}, P-Value: {p_value}\")\n",
    "\n",
    "# group fill rates by priority (second pass)\n",
    "groups_priority = [group[\"fill rate\"] for _, group in df_second.groupby(\"priority\")]\n",
    "f_stat, p_value = f_oneway(*groups_priority)\n",
    "\n",
    "print(f\"ANOVA Test - F-Statistic: {f_stat}, P-Value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "For the **first pass**, the ANOVA test yielded an **F-Statistic of 4519.78** and a **p-value of 0.0**, indicating significant differences in mean `fill rates` across `priority` levels. Similarly, for the **second pass**, the test produced an **F-Statistic of 621.77** with a **p-value of 0.0**, reaffirming that the differences are statistically significant.\n",
    "\n",
    "While the ANOVA test confirms the presence of significant differences, it does not identify which `priority` levels differ from one another. To address this, we performed Tukey's Honest Significant Difference (HSD) test as a post-hoc analysis. This test compares all possible pairs of priority levels to determine where significant differences lie, providing deeper insights into the disparities between groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# conduct Tukey's HSD post-hoc test (first pass)\n",
    "tukey = pairwise_tukeyhsd(endog=df_first[\"fill rate\"], groups=df_first[\"priority\"], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct Tukey's HSD post-hoc test (second pass)\n",
    "tukey = pairwise_tukeyhsd(endog=df_second[\"fill rate\"], groups=df_second[\"priority\"], alpha=0.05)\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After confirming with the ANOVA test that significant differences exist in average `fill rates` across `priority` levels, we used Tukey's Honest Significant Difference (HSD) test as a post-hoc analysis to identify specific pairwise differences between the groups. The results reveal that **all pairwise comparisons between priority levels are statistically significant**, with adjusted p-values below 0.05. This indicates that every priority level differs meaningfully in terms of average `fill rates`.\n",
    "\n",
    "The largest differences are observed between **Priority 1** and the lower priorities. For instance, **Priority 5** has a mean `fill rate` difference of **0.6602** compared to Priority 1 during the first pass, reflecting the substantial disparity in course access between these groups. Similarly, **Priority 6** exhibits a difference of **0.5922** relative to Priority 1. These values demonstrate the advantage that lower-priority students often gain when securing high-demand courses during the later stages of registration.\n",
    "\n",
    "Even adjacent `priority` levels show significant differences. For example, the difference between **Priority 5 and Priority 6** is smaller (**0.2386**) but still statistically significant. This suggests that while students in Priority 5 maintain a slight advantage over those in Priority 6, disparities in course access persist even within these groups. Overall, the results of Tukey's HSD offer meaningful insights into the systematic variations in course utilization across priority levels, aligning with the broader patterns identified in enrollment and `fill rate` analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the statistical analyses, visualizations can offer a clear and intuitive way to communicate key findings. The box plots below illustrate the distribution of `fill rates` across `priority` levels for both the first and second passes. These plots emphasize the variability within each group and highlight trends such as differences in median `fill rates` and the range of course access across priorities. By presenting the data in this format, we reinforce and contextualize the results of the ANOVA and Tukey’s HSD tests, making the observed disparities more accessible to a broader audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# create box plots\n",
    "sns.boxplot(hue=\"priority\", y=\"fill rate\", data=df_first, palette=\"coolwarm\", ax=axes[0])\n",
    "sns.boxplot(hue=\"priority\", y=\"fill rate\", data=df_second, palette=\"coolwarm\", ax=axes[1])\n",
    "\n",
    "axes[0].set_title(\"Box Plot of Fill Rates by Priority (First Pass)\")\n",
    "axes[0].set_xlabel(\"Priority Level\")\n",
    "axes[0].set_ylabel(\"Fill Rate\")\n",
    "\n",
    "axes[1].set_title(\"Box Plot of Fill Rates by Priority (Second Pass)\")\n",
    "axes[1].set_xlabel(\"Priority Level\")\n",
    "axes[1].set_ylabel(\"Fill Rate\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "To examine how `fill rates` differ across priority levels, box plots were used to visualize the distribution of `fill rates` for each priority during the first and second passes. These visualizations provide a detailed view of the range, median, and variability of `fill rates` within each group, while also highlighting any outliers. The results align with prior findings, showing that **lower-priority groups (5 and 6)** tend to have higher median `fill rates` compared to **higher-priority groups (1–4)**. These groups also display greater variability, suggesting a wider range of outcomes in course utilization. In contrast, **higher-priority groups** generally exhibit lower median `fill rates`, with **Priority 1** showing particularly low and tightly distributed values, indicating limited access to courses for this group.\n",
    "\n",
    "Outliers appear across all priority levels in both passes, potentially reflecting courses that either reached full capacity or experienced unexpectedly low enrollment. In the first pass, **Priority 6** has a slightly lower median `fill rate` than Priority 5, consistent with the results of Tukey’s HSD test, which highlighted significant differences even between adjacent priorities. This discrepancy illustrates that, even within lower-priority groups, disparities in course access can persist. Notably, the second pass shows a more balanced distribution of `fill rates` across all priorities, with smaller differences in median values compared to the first pass. This indicates that later registration phases may help mitigate some of the disparities observed in the first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Summary of Findings \n",
    "\n",
    "Our analysis reveals several key insights into the factors influencing course utilization and enrollment dynamics. A strong negative correlation was identified between `fill rates` and available seats, with higher `fill rates` consistently corresponding to fewer available seats. This reinforces `fill rate` as a reliable predictor of seat availability and suggests that students should prioritize securing desired courses during the first pass, which exhibits lower median `fill rates` compared to the second pass. Additionally, the relationship between `fill rates` and course capacity varies by registration phase. During the first pass, smaller-capacity courses tend to fill up faster, reflecting higher demand, while the second pass shows a shift towards prioritizing larger-capacity courses. These findings highlight the dynamic interplay between course capacity and fill rates throughout the registration process.\n",
    "\n",
    "Priority levels and seasonal trends play a significant role in shaping course accessibility. Higher-priority students consistently achieve greater access to courses, as reflected in lower average `fill rates` during the first pass, when seats are more widely available. Conversely, lower-priority groups, particularly Priorities 5 and 6, exhibit higher `fill rates`, especially in the second pass, underscoring their reliance on securing remaining high-demand courses. Seasonal patterns reveal that Fall quarters experience the highest `fill rates`, indicating increased demand at the start of the academic year, while Spring and Summer quarters show greater variability, with some spikes and dips in utilization.\n",
    "\n",
    "Statistical analyses confirmed these trends, with one-way ANOVA tests revealing significant differences in average `fill rates` across priority levels for both passes. The subsequent Tukey’s HSD test identified statistically significant differences between all priority level pairs, with the largest disparities observed between Priority 1 and lower-priority groups. For instance, during the first pass, Priority 5 showed a mean `fill rate` difference of 0.6602 relative to Priority 1. Even within lower-priority groups, disparities persist, as seen in the significant difference of 0.2386 between Priority 5 and Priority 6. These results emphasize the systemic inequities faced by lower-priority groups and the advantages held by higher-priority students during earlier registration phases.\n",
    "\n",
    "Finally, box plots provided additional context by visualizing the distribution of `fill rates` across priority levels for both passes. The first pass revealed greater disparities, with higher variability and tightly distributed values for higher-priority groups. In contrast, the second pass exhibited more balanced distributions, suggesting that later registration phases help reduce some of the disparities observed earlier. Together, these findings offer a comprehensive understanding of course utilization and accessibility, providing valuable insights for optimizing enrollment strategies and addressing inequities in course access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the data is openly accessible, the method of data collection raises ethical considerations regarding automated data retrieval. It is essential to ensure that the scraping process does not access data we are not meant to use. However, the github uses the MIT License, and mentions that anyone is free to use this data. Since this repository is the only thing we scrape, we can address ethical concerns by simply citing this repository as our data source.\n",
    "\n",
    "Although the data has no personally identifiable information (PII), there are some other privacy considerations. For example, enrollment trends and course availability data may indirectly reflect departmental or institutional scheduling strategies. Care must be taken to ensure that any analysis or publication of findings does not inadvertently expose proprietary or sensitive academic information.\n",
    "\n",
    "Furthermore, there are potential biases in the datasets that may need to be addressed, particularly concerning data collection and representation. We may be analyzing data that has an overrepresentation of certain majors and class standings which leads to a biased analysis and recommendations. In addition to that, there may be subjective biases present in course and professor evaluations (CAPES) and instructor ratings from Rate My Professor. To identify and mitigate these biases, we will follow the Data Science Ethics Checklist. This includes conducting thorough data validation and exploratory data analysis (EDA) and implementing access controls to ensure data security as well as integrity. We will ensure that our visualizations and reports honestly represent the data and transparently document our analysis process. Any identified issues will be addressed through corrective measures such as weighting adjustments for underrepresented groups and/or incorporating additional data sources. As we complete all these ethical and privacy concerns throughout our project, we will produce fair, unbiased, and equitable recommendations for future use. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Communication:\n",
    "    - We will communicate via Discord, including texting and calling\n",
    "    - The longest we expect to wait for a response is 24 hours \n",
    "    - We will meet at least once a week\n",
    "    - Most, if not all, meetings will be done virtually\n",
    "- Tone:\n",
    "    - Be direct, but polite\n",
    "        - Ex 1: “I think X is a problem because of Y. Does everyone else see it that way too or am I missing something?”\n",
    "        - Ex 2: “I disagree with that idea because Z. What do you think if instead we try...”\n",
    "- Decision Making:\n",
    "    - Majority vote system for major decisions\n",
    "    - Smaller decisions can be left to the person who is in charge of the task.\n",
    "    - If a teammate is unresponsive when a decision has to be made quickly, it will be made without them using a majority vote.\n",
    "- Tasks:\n",
    "    - Members should first be assigned according to specialization, then others can oversee it to make sure everything aligns with expectations for that task\n",
    "    - We will use GitHub issues for specific tasks and assignment deadlines. \n",
    "- Task completion issues\n",
    "    - If you are struggling to deliver something you promised to do and haven’t made any progress on your own for 30+ minutes, let the group know through discord as soon as possible\n",
    "    - Other group members who have the time outside of their own responsibilities and capability must respond within 24 hours\n",
    "    - If no other members are available for help, the issue will be brought up during the following meeting time to discuss how to solve the problem and possibly reorganize the timeline to reflect that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting | \n",
    "|---|---|---|---|\n",
    "| 2/4  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/8  |  1 PM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/8  | 1 PM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/20  | 6 PM  | Compress and merge Data - Chinmay - 16th Feb then Clean and Tidy Data, Add necessary columns - Anshul | Completion of Data wrangling   |\n",
    "| 2/23  | 12 PM  | Discuss next steps for EDA | Complete project check-in |\n",
    "| 3/6  | 12 PM  | Praveen and Chaela complete EDA by 3/1  | DiscussAnalysis |\n",
    "| 3/9  | 12 PM  | Candice and Chaela complete analysis by 3/14 | Complete project check-in |\n",
    "| 3/14  | 12 PM  | Complete Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 3/16  | 12 PM  | Finalize draft | Have final submission ready |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
